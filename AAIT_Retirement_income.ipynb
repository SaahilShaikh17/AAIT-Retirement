{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaahilShaikh17/AAIT-Retirement/blob/main/AAIT_Retirement_income.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht4TNPj8-AOt"
      },
      "source": [
        "# TEAM AAIT-Retirement Savings Estimator\n",
        "Team members:\n",
        "Saahil Shaikh, Sachit Desai, Sanjana Sharma, Sehaj Saluja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0oRIqxle0lQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74pOha_8fORc"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/SaahilShaikh17/AAIT-Retirement/main/nedgroup_training_data.csv\")\n",
        "df_validation=pd.read_csv(\"https://raw.githubusercontent.com/SaahilShaikh17/AAIT-Retirement/main/nedgroup_validation_data.csv\")\n",
        "df_test=pd.read_csv(\"https://raw.githubusercontent.com/SaahilShaikh17/AAIT-Retirement/main/nedgroup_testing_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPDkf8I-huRp"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnOz98S697FI"
      },
      "outputs": [],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs-LO4K-f2TK"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mWFPql_-Ezg"
      },
      "outputs": [],
      "source": [
        "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "df_validation.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "df_test.drop('Unnamed: 0',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiDXPymm-yCD"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM-EyOey_RkN"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzj8n-FjAONz"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDeCrIZ6AaK2"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOpe4tuJE5ZV"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr6JsCo-IkQ4"
      },
      "source": [
        "Gender, Financially Support Partner, financially support children, years_supporting_child, Years_supporting_Someone_else, Has_emergency_savings, Confidence_Level, spouse_Gender\n",
        "\n",
        "So we have 8 categorical variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceGJ4ntLka1"
      },
      "source": [
        "## Data Issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amH8RfAiJurQ"
      },
      "outputs": [],
      "source": [
        "#Check if there are any duplicated values in our dataset\n",
        "print(df.duplicated().sum())\n",
        "print(df_validation.duplicated().sum())\n",
        "print(df_test.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1vZeUawKeP-"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df_validation.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5rSJCIkKjvo"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(df.duplicated().sum())\n",
        "print(df_validation.duplicated().sum())\n",
        "print(df_test.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cWRc24fnw6F"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkvTjV1J_559"
      },
      "source": [
        "## EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd5pzdoznw6F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPhbgVMbnw6F"
      },
      "source": [
        "\n",
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvd8Oq_qnw6F"
      },
      "source": [
        "<h2>Handling Missing Values</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyWC4Z7Anw6F"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLMDQrRInw6F"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV2CXuprnw6G"
      },
      "outputs": [],
      "source": [
        "# Replace missing values with 'NA' in SPOUSE_GENDER\n",
        "df['SPOUSE_GENDER'].fillna('NA', inplace=True)\n",
        "df_test['SPOUSE_GENDER'].fillna('NA', inplace=True)\n",
        "df_validation['SPOUSE_GENDER'].fillna('NA', inplace=True)\n",
        "\n",
        "# inserting 0 for null values in spouse retirement age\n",
        "df['SPOUSE_RETIREMENT_AGE'] = df['SPOUSE_RETIREMENT_AGE'].fillna(0).astype('int64')\n",
        "df_test['SPOUSE_RETIREMENT_AGE'] = df_test['SPOUSE_RETIREMENT_AGE'].fillna(0).astype('int64')\n",
        "df_validation['SPOUSE_RETIREMENT_AGE'] = df_validation['SPOUSE_RETIREMENT_AGE'].fillna(0).astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oswP6oSMnw6G"
      },
      "outputs": [],
      "source": [
        "df['SPOUSE_RETIREMENT_AGE'].head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpXZqubTnw6G"
      },
      "outputs": [],
      "source": [
        "df[['SPOUSE_GENDER','SPOUSE_RETIREMENT_AGE','SPOUSE_DATE_OF_BIRTH']].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7fPbPhUnw6G"
      },
      "outputs": [],
      "source": [
        "df['SPOUSE_DATE_OF_BIRTH'].head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klMXQ9J2nw6G"
      },
      "outputs": [],
      "source": [
        "# Convert 'SPOUSE_DATE_OF_BIRTH' to pandas datetime format\n",
        "df['SPOUSE_DATE_OF_BIRTH'] = pd.to_datetime(df['SPOUSE_DATE_OF_BIRTH'], errors='coerce')\n",
        "df_test['SPOUSE_DATE_OF_BIRTH'] = pd.to_datetime(df_test['SPOUSE_DATE_OF_BIRTH'], errors='coerce')\n",
        "df_validation['SPOUSE_DATE_OF_BIRTH'] = pd.to_datetime(df_validation['SPOUSE_DATE_OF_BIRTH'], errors='coerce')\n",
        "\n",
        "\n",
        "# Display the DataFrame with the converted datetime column\n",
        "df['SPOUSE_DATE_OF_BIRTH'].head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp1MS4Denw6H"
      },
      "source": [
        "Converting all DOB to year of birth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOvuDGnYnw6H"
      },
      "outputs": [],
      "source": [
        "df['SPOUSE_DATE_OF_BIRTH'] = df['SPOUSE_DATE_OF_BIRTH'].dt.year.astype('Int64')\n",
        "df['SPOUSE_DATE_OF_BIRTH'].fillna(0, inplace=True)\n",
        "\n",
        "df_test['SPOUSE_DATE_OF_BIRTH'] = df_test['SPOUSE_DATE_OF_BIRTH'].dt.year.astype('Int64')\n",
        "df_test['SPOUSE_DATE_OF_BIRTH'].fillna(0, inplace=True)\n",
        "\n",
        "df_validation['SPOUSE_DATE_OF_BIRTH'] = df_validation['SPOUSE_DATE_OF_BIRTH'].dt.year.astype('Int64')\n",
        "df_validation['SPOUSE_DATE_OF_BIRTH'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ireAb8lJnw6H"
      },
      "outputs": [],
      "source": [
        "df['SPOUSE_DATE_OF_BIRTH'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_3PwPDcnw6H"
      },
      "outputs": [],
      "source": [
        "df[['SPOUSE_GENDER','SPOUSE_RETIREMENT_AGE','SPOUSE_DATE_OF_BIRTH']].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lgd4JPFHnw6I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ybLgGHnw6I"
      },
      "source": [
        "<h2>Standardisation</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4jbajKQnw6I"
      },
      "outputs": [],
      "source": [
        "# Extract numerical columns for standardization\n",
        "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the numerical columns\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "df_test[numerical_columns] = scaler.fit_transform(df_test[numerical_columns])\n",
        "df_validation[numerical_columns] = scaler.fit_transform(df_validation[numerical_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46Dp1YCZnw6I"
      },
      "outputs": [],
      "source": [
        "objs = df.select_dtypes(include = \"object\").columns\n",
        "print(objs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOJcHU-Mnw6I"
      },
      "source": [
        "over here-\n",
        "\n",
        "GENDER and SPOUSE_GENDER should be one hot encoded and\n",
        "\n",
        "FINANCIALLY_SUPPORT_PARTNER, FINANCIALLY_SUPPORT_CHILDREN, HAS_EMERGENCY_SAVINGS, HAS_EMERGENCY_SAVINGS, CRITICAL_ILLNESS and SPOUSE_DATE_OF_BIRTH should be label encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2POuYAjUnw6J"
      },
      "source": [
        "<h2>Encoding of categorical variables</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL02HyFvnw6J"
      },
      "outputs": [],
      "source": [
        "# One-hot-encoding\n",
        "df = pd.get_dummies(df, columns=['GENDER', 'SPOUSE_GENDER'])\n",
        "df_validation = pd.get_dummies(df_validation, columns=['GENDER', 'SPOUSE_GENDER'])\n",
        "df_test = pd.get_dummies(df_test, columns=['GENDER', 'SPOUSE_GENDER'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBgCmtJbnw6J"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSWhaNQfnw6J"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encode = LabelEncoder()\n",
        "\n",
        "for col in objs[1:-1]:\n",
        "  df[col] = encode.fit_transform(df[col].astype(str))\n",
        "  df_validation[col] = encode.fit_transform(df_validation[col].astype(str))\n",
        "  df_test[col] = encode.fit_transform(df_test[col].astype(str))\n",
        "\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1dpt53cnw6J"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE7VJkhgnw6J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLUCDX1nnw6K"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-fvXTqDnw6K"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0iKglBQnw6K"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxZ1gQ1knw6K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm4SI9Ianw6K"
      },
      "outputs": [],
      "source": [
        "X_train= df.drop(['TARGET_MONTHLY_INCOME'],axis=1)\n",
        "Y_train= df['TARGET_MONTHLY_INCOME']\n",
        "X_test= df_test.drop(['TARGET_MONTHLY_INCOME'],axis=1)\n",
        "Y_test=df_test['TARGET_MONTHLY_INCOME']\n",
        "X_val= df_validation.drop(['TARGET_MONTHLY_INCOME'],axis=1)\n",
        "Y_val=df_validation['TARGET_MONTHLY_INCOME']\n",
        "print(Y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Grcotoznw6K"
      },
      "source": [
        "Our target variable is Target_monthly_income which the targeted monthly income the customer should have in order to reach their expected retirement fund value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i3EKCdynw6L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUUNxX-snw6L"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4dqKn_Nnw6L"
      },
      "outputs": [],
      "source": [
        "model=RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dal3io53nw6L"
      },
      "outputs": [],
      "source": [
        "Y_pred=model.predict(X_val)\n",
        "\n",
        "rmse= mean_squared_error(Y_val, Y_pred, squared=False)\n",
        "mae= mean_absolute_error(Y_val, Y_pred)\n",
        "r2=r2_score(Y_val, Y_pred)\n",
        "print(\"The Root mean squared error is: \",rmse)\n",
        "print(\"The Mean absolute error is: \",mae)\n",
        "print(\"The R-2 Score is: \",r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU4nNXF6nw6L"
      },
      "outputs": [],
      "source": [
        "print(\"First 10 Predicted vs Real Values:\")\n",
        "for i in range(10):\n",
        "    print(f\"Predicted: {Y_pred[i]:.2f}, Actual: {Y_test.iloc[i]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iVnwR8jnw6L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the number of folds (f)\n",
        "f = 5\n",
        "\n",
        "# Initialize KFold object\n",
        "kf = KFold(n_splits=f, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize empty lists to store performance metrics\n",
        "rmse_scores = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    # Split combined data into training and validation sets\n",
        "    X_fold_train = X_train.iloc[train_index]\n",
        "    Y_fold_train = Y_train.iloc[train_index]\n",
        "\n",
        "    X_fold_val = X_train.iloc[val_index]\n",
        "    Y_fold_val = Y_train.iloc[val_index]\n",
        "\n",
        "    # Train the model on the training fold\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_fold_train, Y_fold_train)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    predictions_fold_val = model.predict(X_fold_val)\n",
        "\n",
        "    # Calculate metrics for the validation fold\n",
        "    rmse_fold = mean_squared_error(Y_fold_val, predictions_fold_val, squared=False)\n",
        "    mae_fold = mean_absolute_error(Y_fold_val, predictions_fold_val)\n",
        "    r2_fold = r2_score(Y_fold_val, predictions_fold_val)\n",
        "\n",
        "    # Append metrics to the lists\n",
        "    rmse_scores.append(rmse_fold)\n",
        "    mae_scores.append(mae_fold)\n",
        "    r2_scores.append(r2_fold)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "average_rmse = np.mean(rmse_scores)\n",
        "average_mae = np.mean(mae_scores)\n",
        "average_r2 = np.mean(r2_scores)\n",
        "\n",
        "print('Average RMSE:', average_rmse)\n",
        "print('Average MAE:', average_mae)\n",
        "print('Average R2:', average_r2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXUf6CjEnw6L"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store performance metrics for testing set\n",
        "test_rmse_scores = []\n",
        "test_mae_scores = []\n",
        "test_r2_scores = []\n",
        "\n",
        "# Perform K-fold cross-validation on the testing set\n",
        "for train_index, val_index in kf.split(X_test):\n",
        "    # Split testing data into training and validation sets\n",
        "    X_fold_train_test = X_test.iloc[train_index]\n",
        "    Y_fold_train_test = Y_test.iloc[train_index]\n",
        "\n",
        "    X_fold_val_test = X_test.iloc[val_index]\n",
        "    Y_fold_val_test = Y_test.iloc[val_index]\n",
        "\n",
        "    # Train the model on the training fold of testing set\n",
        "    model_test = RandomForestRegressor(random_state=42)\n",
        "    model_test.fit(X_fold_train_test, Y_fold_train_test)\n",
        "\n",
        "    # Make predictions on the validation fold of testing set\n",
        "    predictions_fold_val_test = model_test.predict(X_fold_val_test)\n",
        "\n",
        "    # Calculate metrics for the validation fold of testing set\n",
        "    rmse_fold_test = mean_squared_error(Y_fold_val_test, predictions_fold_val_test, squared=False)\n",
        "    mae_fold_test = mean_absolute_error(Y_fold_val_test, predictions_fold_val_test)\n",
        "    r2_fold_test = r2_score(Y_fold_val_test, predictions_fold_val_test)\n",
        "\n",
        "    # Append metrics to the lists\n",
        "    test_rmse_scores.append(rmse_fold_test)\n",
        "    test_mae_scores.append(mae_fold_test)\n",
        "    test_r2_scores.append(r2_fold_test)\n",
        "\n",
        "# Calculate average metrics across all folds for testing set\n",
        "average_test_rmse = np.mean(test_rmse_scores)\n",
        "average_test_mae = np.mean(test_mae_scores)\n",
        "average_test_r2 = np.mean(test_r2_scores)\n",
        "\n",
        "print('Average Test RMSE:', average_test_rmse)\n",
        "print('Average Test MAE:', average_test_mae)\n",
        "print('Average Test R2:', average_test_r2)\n",
        "print(test_r2_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71AxTDdQnw6M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8G3eHvinw6M"
      },
      "outputs": [],
      "source": [
        "#To get the parameters of the model\n",
        "model.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VhokF74nw6N"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8dD59YRnw6N"
      },
      "outputs": [],
      "source": [
        "tree=RandomForestRegressor(max_depth=25,bootstrap=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNb-Ft4unw6N"
      },
      "outputs": [],
      "source": [
        "final_cols = ['RETIREMENT_AGE', 'RETIREMENT_FUND_VALUE', 'DEPT_VALUE',\n",
        "       'SPARE_CASH_VALUE', 'OTHER_MONTHLY_SUPPORTING_VALUE',\n",
        "       'CRITICAL_ILLNESS', 'SPOUSE_GENDER_Female', 'SPOUSE_GENDER_Male', 'SPOUSE_GENDER_NA', 'SPOUSE_RETIREMENT_AGE',\n",
        "       'SPOUSE_DATE_OF_BIRTH', 'INTERNATIONAL_CASH_UNIT_TRUST',\n",
        "       'SA_EQUITY_LAP', 'SA_BOND_LAP', 'SA_CASH_LAP', 'INTERNATIONAL_CASH_LAP',\n",
        "       'LA_EAC_PA_INCL_VAT', 'UNIT_TRUST_EAC_PA_INCL_VAT']\n",
        "df_selected=df[final_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hZIDnV2nw6N"
      },
      "outputs": [],
      "source": [
        "x = df.drop('TARGET_MONTHLY_INCOME', axis=1)\n",
        "y = df['TARGET_MONTHLY_INCOME']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYGV-5DYnw6N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}